{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Expressions for different types of tumor\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/gene_protein_cancer.jpg\" alt=\"image\" width=\"300\" height=\"200\">\n",
    "</div>\n",
    "[image src: https://www.cancer.gov/about-cancer/causes-prevention/genetics]\n",
    "\n",
    "This project aims to identify different gene expressions associated to 5 types of tumor : \n",
    "- BRCA (Breast Cancer): Family of Genes (BRCA1 and BRCA2) are known as tumor suppresors. But mutation in these genes cause cancer.\n",
    "- KIRC (Kidney Renal Clear Cell Carcinoma): \n",
    "- COAD (Colon Adenocarcinoma)\n",
    "- LUAD (Lung Adenocarcinoma)\n",
    "- PRAD (Prostate Adenocarcinoma)\n",
    "\n",
    "The dataset is sourced from https://archive.ics.uci.edu/dataset/401/gene+expression+cancer+rna+seq.\n",
    "The original dataset is published at https://www.synapse.org/Synapse:syn300013/discussion/threadId=5455. The Gene names in the dataset are dummy names. The actual gene names are at https://www.ncbi.nlm.nih.gov/gene, per this discussion thread https://www.synapse.org/Synapse:syn300013/discussion/threadId=5455. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "DATA_ANALYSIS_DIR = \"data-analysis/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.utils.ArrayUtils import get_list_of_items_in_both_lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from files\n",
    "url_reconstructed = 'TCGA-PANCAN-HiSeq-801x20531/data.csv'\n",
    "\n",
    "# url = 'https://drive.google.com/file/d/1VXyhDXpYT8G2Buhkc6kBjw93CLG1y1f0/view?usp=drive_link'\n",
    "# # Use only the Id and reconstruct the URL\n",
    "# url_reconstructed = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "df = pd.read_csv(url_reconstructed)\n",
    "tumor_df = pd.read_csv('TCGA-PANCAN-HiSeq-801x20531/labels.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataframe before adding the class column: {df.info()}\")\n",
    "print(f\"Total # of columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy over the Class column into the main dataframe\n",
    "df = df.rename(columns={'Unnamed: 0': 'sample'})\n",
    "tumor_df = tumor_df.rename(columns={'Unnamed: 0': 'sample'})\n",
    "df['Class'] = np.where( (df['sample'] == tumor_df['sample']), tumor_df['Class'], df['sample'])\n",
    "\n",
    "# df['Class'] = tumor_df['Class']\n",
    "# print(f\"Total # of columns: {len(df.columns)}\")\n",
    "\n",
    "df.drop(columns=['sample'], axis=1, inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "### Data Cleaning and PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data : \n",
    "- No NANs as stated on the data source page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with 0 values\n",
    "zero_cols = df.columns[(df == 0).all()]\n",
    "print(f\"# of columns with all 0s in them : {zero_cols}\")\n",
    "df = df.drop(columns=zero_cols, axis=1)\n",
    "print(f\"# of columns with all 0s in them : {df.columns[(df == 0).all()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post cleanup, write the data to file\n",
    "df.to_csv(DATA_ANALYSIS_DIR + \"df_PostColumnCleanup.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class analysis\n",
    "class_unique_vals = df['Class'].unique()\n",
    "assert(len(class_unique_vals) == 5)\n",
    "\n",
    "# print the distribution\n",
    "print(f\"Distribution of Class values: \\n{df['Class'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split -\n",
    "X = df.drop(columns=['Class'], axis=1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df['Class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate and Multivariate Analysis\n",
    "Given the large # of variables (columns), charting each out against other can be a challenge. Hence printing key insights such as stats to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "df_desc = df.describe()\n",
    "df_desc_t = df_desc.T\n",
    "df_desc_t.to_csv(DATA_ANALYSIS_DIR + \"df_describe.csv\")\n",
    "\n",
    "df_desc_zscore = df_desc.apply(stats.zscore)\n",
    "df_desc_zscore.T.to_csv(DATA_ANALYSIS_DIR + \"rawdata_zscore.csv\")\n",
    "# df_desc['upperbound'] = df_desc['mean'] + 3*(df_desc['std'])\n",
    "# df_desc['lowerbound'] = df_desc['mean'] - 3*(df_desc['std'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Identify Correlation across features / columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NOTE : This take quite some time to run 11+ mins\n",
    "corr_df = X.corr()\n",
    "corr_df.to_csv(DATA_ANALYSIS_DIR + 'features_corr_matrix.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any Features with Correlation value= NaN ?\n",
    "# -- In total there are 267 cols with 0 values, since they are deleted, result is zero\n",
    "corr_nan_list = corr_df.columns[corr_df.isna().all()].tolist()\n",
    "print(corr_nan_list)\n",
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we run without reducing any dimensions, i.e directly on all of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Point EDA : Observations thus far\n",
    "- Data is clean\n",
    "- Some of the columns have 0 values, which means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Use basic model\n",
    "rd_classifier = RandomForestClassifier(random_state=42, oob_score=True)\n",
    "rd_classifier.fit(X_train, y_train)\n",
    "rd_preds = rd_classifier.predict(X_test)\n",
    "report = classification_report(y_test, rd_preds)\n",
    "rd_preds_prob = rd_classifier.predict_proba(X_test)\n",
    "\n",
    "rd_oob_score = rd_classifier.oob_score_\n",
    "rd_feature_imp = rd_classifier.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot Confusion Matrix\n",
    "def plot_confusion_matrix(conf_matrix, labels, title=\"Confusion Matrix\"):\n",
    "\n",
    "    conf_matrix = conf_matrix[::-1]\n",
    "    # labels = labels[::-1]\n",
    "\n",
    "    #heat map\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=conf_matrix,\n",
    "        x=labels,\n",
    "        y=labels[::-1], #reverse the order to align labels with way Conf matrix is output\n",
    "        colorscale='Rainbow', # 'Hot', # 'YlOrRd', # 'YlGnBu', #'Viridis',\n",
    "        texttemplate=\"%{z}\",\n",
    "        textfont={\"size\": 10}\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text = title,\n",
    "        xaxis_title=\"Predicted Class\",\n",
    "        yaxis_title=\"Actual Class\",\n",
    "        # xaxis={'side': 'top'},\n",
    "        # yaxis={'autorange': 'reversed'},\n",
    "        width=500,\n",
    "        height=500,\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - interpreting Results\n",
    "print(f\"Out of Bag score: {rd_oob_score}\")\n",
    "print(f\"Feature Importances: {rd_feature_imp.sort()}\")\n",
    "print(f\"Accuracy : {rd_classifier.score(X_test, y_test)}\")\n",
    "print(\"Classification report: \\n\", report)\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=rd_preds, labels=class_unique_vals)\n",
    "plot_confusion_matrix(cm, labels=class_unique_vals, title='RandomForest without PCA : Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under Curve - REF : https://www.geeksforgeeks.org/interpreting-random-forest-classification-results/\n",
    "target_vals = y_test.unique()\n",
    "# y_test_bin = label_binarize(y_test, classes=[0,1,2,3,4])\n",
    "label_binzer = LabelBinarizer()\n",
    "label_binzer.fit(y_test)\n",
    "y_test_bin = label_binzer.transform(y_test)\n",
    "# print(y_test_bin)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "# print(f\"y_test_bin : {len(y_test_bin[:, 0])}\")\n",
    "# print(f\"rd_preds_prob : {rd_preds_prob[:, 0]}\")\n",
    "# print(f\"y_test_bin : {len(y_test_bin[:, 1])}\")\n",
    "# print(f\"rd_preds_prob : {rd_preds_prob[:, 1]}\")\n",
    "\n",
    "\n",
    "for index in range(len(target_vals)):\n",
    "    fpr[index], tpr[index], _ = roc_curve(y_test_bin[:, index], rd_preds_prob[:, index])\n",
    "    # print(f\"FPR at {index}: \\n{fpr[index]}\")\n",
    "    # print(f\"TPR at {index}: \\n{tpr[index]}\")\n",
    "    roc_auc[index] = auc(fpr[index], tpr[index])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "for index in range(len(target_vals)) :\n",
    "    plt.plot(fpr[index], tpr[index], lw=2, label=f\"ROC curve of class {target_vals[index]} (area = {roc_auc[index]:.2f})\")\n",
    "\n",
    "# plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characterstic for Tumor classes')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
